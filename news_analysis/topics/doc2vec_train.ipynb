{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing as mp\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import parmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_index_to_name_map = {\n",
    "    0: 'Agriculture, animals, food and rural affairs',\n",
    "    1: 'Asylum, immigration and nationality',\n",
    "    2: 'Business, industry and consumers',\n",
    "    3: 'Communities and families',\n",
    "    4: 'Crime, civil law, justice and rights',\n",
    "    5: 'Culture, media and sport',\n",
    "    6: 'Defence',\n",
    "    7: 'Economy and finance',\n",
    "    8: 'Education',\n",
    "    9: 'Employment and training',\n",
    "    10: 'Energy and environment',\n",
    "    11: 'European Union',\n",
    "    12: 'Health services and medicine',\n",
    "    13: 'Housing and planning',\n",
    "    14: 'International affairs',\n",
    "    15: 'Parliament, government and politics',\n",
    "    16: 'Science and technology',\n",
    "    17: 'Social security and pensions',\n",
    "    18: 'Social services',\n",
    "    19: 'Transport',\n",
    "    20: 'Others'\n",
    "}\n",
    "topics_name_to_index_map = {y:x for x,y in topics_index_to_name_map.items()}\n",
    "\n",
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, FILTERS)\n",
    "\n",
    "def preprocess(topic):\n",
    "    ret = []\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    if '|' in topic:\n",
    "        topics = topic.split('|')\n",
    "        t = topics[0]\n",
    "        t = t.strip()\n",
    "        return topics_name_to_index_map[t]\n",
    "        \n",
    "    return topics_name_to_index_map[topic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data!!\n"
     ]
    }
   ],
   "source": [
    "print('preparing data!!')\n",
    "df2 = pd.read_csv('./data/2012_debate.csv')\n",
    "df3 = pd.read_csv('./data/2013_debate.csv')\n",
    "df = pd.concat([df2, df3])\n",
    "# df = df.drop(['date'], axis=1)\n",
    "df = df.drop(df[df.topic == 'admin'].index)\n",
    "df = df.drop(df[df.transcript.str.split().map(len) < 10].index)\n",
    "df['topic'] = df.apply(lambda row: preprocess(row['topic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parliament, government and politics</th>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime, civil law, justice and rights</th>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health services and medicine</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International affairs</th>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economy and finance</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business, industry and consumers</th>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communities and families</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defence</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy and environment</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment and training</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culture, media and sport</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture, animals, food and rural affairs</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>European Union</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asylum, immigration and nationality</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Housing and planning</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science and technology</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social security and pensions</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social services</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              count\n",
       "Parliament, government and politics             497\n",
       "Crime, civil law, justice and rights            473\n",
       "Health services and medicine                    278\n",
       "International affairs                           260\n",
       "Economy and finance                             234\n",
       "Business, industry and consumers                205\n",
       "Communities and families                        199\n",
       "Defence                                         183\n",
       "Energy and environment                          181\n",
       "Employment and training                         179\n",
       "Education                                       176\n",
       "Transport                                       172\n",
       "Others                                          155\n",
       "Culture, media and sport                        143\n",
       "Agriculture, animals, food and rural affairs     86\n",
       "European Union                                   52\n",
       "Asylum, immigration and nationality              42\n",
       "Housing and planning                             29\n",
       "Science and technology                           20\n",
       "Social security and pensions                     14\n",
       "Social services                                  10"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df['topic'].value_counts()\n",
    "topic_counts = {topics_index_to_name_map[key]: counts[key] for key in counts.keys()}\n",
    "counts_df = pd.DataFrame.from_dict(topic_counts, orient='index', columns=['count'])\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>13.  What assessment he has made of the effect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>14.  How many young apprenticeship starts ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I beg to move,  That this House believes that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18.  What assessment he has made of recent tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>(Urgent Question): To ask my right hon. Friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>11</td>\n",
       "      <td>10.  How many requests for a reconsideration o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>15</td>\n",
       "      <td>4.  What steps she is taking to reduce workles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>12</td>\n",
       "      <td>4.  What recent representations he has receive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>20</td>\n",
       "      <td>(Urgent Question): To ask the Chancellor of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>4</td>\n",
       "      <td>7.  Whether he plans to extend the use of priv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3588 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                         transcript\n",
       "0         7  13.  What assessment he has made of the effect...\n",
       "1         8  14.  How many young apprenticeship starts ther...\n",
       "2         2  I beg to move,  That this House believes that ...\n",
       "3         3  18.  What assessment he has made of recent tre...\n",
       "4        12  (Urgent Question): To ask my right hon. Friend...\n",
       "...     ...                                                ...\n",
       "3583     11  10.  How many requests for a reconsideration o...\n",
       "3584     15  4.  What steps she is taking to reduce workles...\n",
       "3585     12  4.  What recent representations he has receive...\n",
       "3586     20  (Urgent Question): To ask the Chancellor of th...\n",
       "3587      4  7.  Whether he plans to extend the use of priv...\n",
       "\n",
       "[3588 rows x 2 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['transcript'].values\n",
    "Y = df['topic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3596it [00:02, 1506.92it/s]                          \n"
     ]
    }
   ],
   "source": [
    "print('preprocessing data!!')\n",
    "#preprocessed_X = list(map(preprocess_text, X))\n",
    "preprocessed_X = parmap.map(preprocess_text, X, pm_pbar=True)\n",
    "tagged_X = [models.doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training doc2vec\n"
     ]
    }
   ],
   "source": [
    "print('training doc2vec')\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=3, workers=mp.cpu_count(), epochs=40)\n",
    "doc2vec_model.build_vocab(tagged_X)\n",
    "doc2vec_model.train(tagged_X, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "doc2vec_model.save('doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input Data for Neural Net Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "input_Y = Y.reshape(-1,1)\n",
    "enc.fit(input_Y)\n",
    "input_Y = enc.transform(input_Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3596it [00:15, 230.86it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (2870, 100)\n",
      "y_train:  (2870, 21)\n",
      "X_test:  (718, 100)\n",
      "y_test:  (718, 21)\n"
     ]
    }
   ],
   "source": [
    "print('preparing inputs')\n",
    "\n",
    "def get_doc_vec(doc):\n",
    "    return doc2vec_model.infer_vector(doc.words)\n",
    "\n",
    "inputs = parmap.map(get_doc_vec, tagged_X, pm_pbar=True)\n",
    "\n",
    "# for x in tagged_X:\n",
    "#     topic_vec = doc2vec_model.infer_vector(x.words)\n",
    "#     inputs.append(topic_vec)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, input_Y, stratify=input_Y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(100)),\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(21, activation='softmax')\n",
    "    ])\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, name='categorical_crossentropy')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2870 samples, validate on 718 samples\n",
      "Epoch 1/200\n",
      "2870/2870 [==============================] - 2s 529us/sample - loss: 6.0981 - accuracy: 0.1711 - val_loss: 4.3858 - val_accuracy: 0.3148\n",
      "Epoch 2/200\n",
      "2870/2870 [==============================] - 0s 80us/sample - loss: 3.4250 - accuracy: 0.4453 - val_loss: 2.7048 - val_accuracy: 0.5599\n",
      "Epoch 3/200\n",
      "2870/2870 [==============================] - 0s 79us/sample - loss: 2.2984 - accuracy: 0.5976 - val_loss: 2.0756 - val_accuracy: 0.6295\n",
      "Epoch 4/200\n",
      "2870/2870 [==============================] - 0s 77us/sample - loss: 1.8704 - accuracy: 0.6645 - val_loss: 1.8352 - val_accuracy: 0.6407\n",
      "Epoch 5/200\n",
      "2870/2870 [==============================] - 0s 80us/sample - loss: 1.6973 - accuracy: 0.6843 - val_loss: 1.7212 - val_accuracy: 0.6657\n",
      "Epoch 6/200\n",
      "2870/2870 [==============================] - 0s 81us/sample - loss: 1.6060 - accuracy: 0.6941 - val_loss: 1.6637 - val_accuracy: 0.6643\n",
      "Epoch 7/200\n",
      "2870/2870 [==============================] - 0s 81us/sample - loss: 1.5507 - accuracy: 0.6948 - val_loss: 1.6277 - val_accuracy: 0.6755\n",
      "Epoch 8/200\n",
      "2870/2870 [==============================] - 0s 72us/sample - loss: 1.5035 - accuracy: 0.6969 - val_loss: 1.5872 - val_accuracy: 0.6643\n",
      "Epoch 9/200\n",
      "2870/2870 [==============================] - 0s 63us/sample - loss: 1.4691 - accuracy: 0.7049 - val_loss: 1.5568 - val_accuracy: 0.6811\n",
      "Epoch 10/200\n",
      "2870/2870 [==============================] - 0s 59us/sample - loss: 1.4396 - accuracy: 0.7101 - val_loss: 1.5318 - val_accuracy: 0.6880\n",
      "Epoch 11/200\n",
      "2870/2870 [==============================] - 0s 53us/sample - loss: 1.4117 - accuracy: 0.7146 - val_loss: 1.5182 - val_accuracy: 0.6783\n",
      "Epoch 12/200\n",
      "2870/2870 [==============================] - 0s 52us/sample - loss: 1.3846 - accuracy: 0.7167 - val_loss: 1.4948 - val_accuracy: 0.6713\n",
      "Epoch 13/200\n",
      "2870/2870 [==============================] - 0s 46us/sample - loss: 1.3604 - accuracy: 0.7185 - val_loss: 1.4842 - val_accuracy: 0.6797\n",
      "Epoch 14/200\n",
      "2870/2870 [==============================] - 0s 46us/sample - loss: 1.3376 - accuracy: 0.7244 - val_loss: 1.4712 - val_accuracy: 0.6741\n",
      "Epoch 15/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.3199 - accuracy: 0.7254 - val_loss: 1.4650 - val_accuracy: 0.6852\n",
      "Epoch 16/200\n",
      "2870/2870 [==============================] - 0s 44us/sample - loss: 1.3036 - accuracy: 0.7247 - val_loss: 1.4520 - val_accuracy: 0.6825\n",
      "Epoch 17/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2869 - accuracy: 0.7352 - val_loss: 1.4388 - val_accuracy: 0.6630\n",
      "Epoch 18/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2757 - accuracy: 0.7293 - val_loss: 1.4121 - val_accuracy: 0.6838\n",
      "Epoch 19/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2584 - accuracy: 0.7258 - val_loss: 1.4066 - val_accuracy: 0.6964\n",
      "Epoch 20/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2504 - accuracy: 0.7352 - val_loss: 1.4063 - val_accuracy: 0.6741\n",
      "Epoch 21/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2352 - accuracy: 0.7345 - val_loss: 1.3939 - val_accuracy: 0.6769\n",
      "Epoch 22/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.2222 - accuracy: 0.7341 - val_loss: 1.3925 - val_accuracy: 0.6825\n",
      "Epoch 23/200\n",
      "2870/2870 [==============================] - 0s 47us/sample - loss: 1.2085 - accuracy: 0.7394 - val_loss: 1.3836 - val_accuracy: 0.6894\n",
      "Epoch 24/200\n",
      "2870/2870 [==============================] - 0s 45us/sample - loss: 1.1990 - accuracy: 0.7429 - val_loss: 1.3790 - val_accuracy: 0.6727\n",
      "Epoch 25/200\n",
      "2870/2870 [==============================] - 0s 47us/sample - loss: 1.1947 - accuracy: 0.7456 - val_loss: 1.3745 - val_accuracy: 0.6838\n",
      "Epoch 26/200\n",
      "2870/2870 [==============================] - 0s 53us/sample - loss: 1.1795 - accuracy: 0.7418 - val_loss: 1.3709 - val_accuracy: 0.6797\n",
      "Epoch 27/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1715 - accuracy: 0.7422 - val_loss: 1.3713 - val_accuracy: 0.6797\n",
      "Epoch 28/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1632 - accuracy: 0.7477 - val_loss: 1.3577 - val_accuracy: 0.6797\n",
      "Epoch 29/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1535 - accuracy: 0.7509 - val_loss: 1.3517 - val_accuracy: 0.6866\n",
      "Epoch 30/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1462 - accuracy: 0.7502 - val_loss: 1.3616 - val_accuracy: 0.6811\n",
      "Epoch 31/200\n",
      "2870/2870 [==============================] - 0s 53us/sample - loss: 1.1377 - accuracy: 0.7449 - val_loss: 1.3424 - val_accuracy: 0.6797\n",
      "Epoch 32/200\n",
      "2870/2870 [==============================] - 0s 52us/sample - loss: 1.1304 - accuracy: 0.7443 - val_loss: 1.3428 - val_accuracy: 0.6838\n",
      "Epoch 33/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1245 - accuracy: 0.7557 - val_loss: 1.3261 - val_accuracy: 0.6880\n",
      "Epoch 34/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1158 - accuracy: 0.7530 - val_loss: 1.3259 - val_accuracy: 0.6866\n",
      "Epoch 35/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.1100 - accuracy: 0.7495 - val_loss: 1.3264 - val_accuracy: 0.6838\n",
      "Epoch 36/200\n",
      "2870/2870 [==============================] - 0s 55us/sample - loss: 1.1037 - accuracy: 0.7512 - val_loss: 1.3253 - val_accuracy: 0.6880\n",
      "Epoch 37/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.0963 - accuracy: 0.7554 - val_loss: 1.3327 - val_accuracy: 0.6755\n",
      "Epoch 38/200\n",
      "2870/2870 [==============================] - 0s 53us/sample - loss: 1.0946 - accuracy: 0.7505 - val_loss: 1.3151 - val_accuracy: 0.6866\n",
      "Epoch 39/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.0872 - accuracy: 0.7578 - val_loss: 1.3200 - val_accuracy: 0.6852\n",
      "Epoch 40/200\n",
      "2870/2870 [==============================] - 0s 55us/sample - loss: 1.0825 - accuracy: 0.7554 - val_loss: 1.3127 - val_accuracy: 0.6852\n",
      "Epoch 41/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.0733 - accuracy: 0.7561 - val_loss: 1.3101 - val_accuracy: 0.6894\n",
      "Epoch 42/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.0660 - accuracy: 0.7575 - val_loss: 1.3126 - val_accuracy: 0.6838\n",
      "Epoch 43/200\n",
      "2870/2870 [==============================] - 0s 57us/sample - loss: 1.0583 - accuracy: 0.7606 - val_loss: 1.3193 - val_accuracy: 0.6769\n",
      "Epoch 44/200\n",
      "2870/2870 [==============================] - 0s 54us/sample - loss: 1.0527 - accuracy: 0.7634 - val_loss: 1.3185 - val_accuracy: 0.6797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5ca446d090>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_network()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=200, callbacks=[callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./topics_classifier_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
