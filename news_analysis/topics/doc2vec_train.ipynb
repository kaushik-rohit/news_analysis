{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing as mp\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import parmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_index_to_name_map = {\n",
    "    0: 'Agriculture, animals, food and rural affairs',\n",
    "    1: 'Asylum, immigration and nationality',\n",
    "    2: 'Business, industry and consumers',\n",
    "    3: 'Communities and families',\n",
    "    4: 'Crime, civil law, justice and rights',\n",
    "    5: 'Culture, media and sport',\n",
    "    6: 'Defence',\n",
    "    7: 'Economy and finance',\n",
    "    8: 'Education',\n",
    "    9: 'Employment and training',\n",
    "    10: 'Energy and environment',\n",
    "    11: 'European Union',\n",
    "    12: 'Health services and medicine',\n",
    "    13: 'Housing and planning',\n",
    "    14: 'International affairs',\n",
    "    15: 'Parliament, government and politics',\n",
    "    16: 'Science and technology',\n",
    "    17: 'Social security and pensions',\n",
    "    18: 'Social services',\n",
    "    19: 'Transport',\n",
    "    20: 'Others'\n",
    "}\n",
    "topics_name_to_index_map = {y:x for x,y in topics_index_to_name_map.items()}\n",
    "\n",
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, FILTERS)\n",
    "\n",
    "def preprocess(topic):\n",
    "    ret = []\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    if '|' in topic:\n",
    "        topics = topic.split('|')\n",
    "        t = topics[0]\n",
    "        t = t.strip()\n",
    "        return topics_name_to_index_map[t]\n",
    "        \n",
    "    return topics_name_to_index_map[topic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data!!\n"
     ]
    }
   ],
   "source": [
    "print('preparing data!!')\n",
    "df2 = pd.read_csv('./data/2015_debate.csv')\n",
    "df3 = pd.read_csv('./data/2016_debate.csv')\n",
    "df = pd.concat([df2, df3])\n",
    "# df = df.drop(['date'], axis=1)\n",
    "df = df.drop(df[df.topic == 'admin'].index)\n",
    "df = df.drop(df[df.transcript.str.split().map(len) < 10].index)\n",
    "df['topic'] = df.apply(lambda row: preprocess(row['topic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Parliament, government and politics</th>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime, civil law, justice and rights</th>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health services and medicine</th>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International affairs</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economy and finance</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communities and families</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business, industry and consumers</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy and environment</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defence</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment and training</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Culture, media and sport</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>European Union</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture, animals, food and rural affairs</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asylum, immigration and nationality</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science and technology</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Housing and planning</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social security and pensions</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Social services</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              count\n",
       "Parliament, government and politics             488\n",
       "Crime, civil law, justice and rights            462\n",
       "Health services and medicine                    267\n",
       "International affairs                           245\n",
       "Economy and finance                             199\n",
       "Transport                                       196\n",
       "Communities and families                        194\n",
       "Education                                       190\n",
       "Business, industry and consumers                189\n",
       "Energy and environment                          173\n",
       "Defence                                         165\n",
       "Employment and training                         158\n",
       "Culture, media and sport                        141\n",
       "Others                                          140\n",
       "European Union                                   96\n",
       "Agriculture, animals, food and rural affairs     80\n",
       "Asylum, immigration and nationality              54\n",
       "Science and technology                           27\n",
       "Housing and planning                             27\n",
       "Social security and pensions                     19\n",
       "Social services                                   8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df['topic'].value_counts()\n",
    "topic_counts = {topics_index_to_name_map[key]: counts[key] for key in counts.keys()}\n",
    "counts_df = pd.DataFrame.from_dict(topic_counts, orient='index', columns=['count'])\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>7.  What progress the Government are making on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>12.  What progress his Department has made on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3.  What steps she is taking to ensure that il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>15.  What additional investment the Government...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>11.  If he will commission research on the pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>4</td>\n",
       "      <td>I am grateful for this opportunity to raise in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>3</td>\n",
       "      <td>10.  What steps his Department has taken to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>7</td>\n",
       "      <td>4.  What progress has been made on implementin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>14</td>\n",
       "      <td>3.  What diplomatic support the Government are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>11</td>\n",
       "      <td>5. What rights he plans to secure for UK citiz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic                                         transcript\n",
       "0         8  7.  What progress the Government are making on...\n",
       "1         6  12.  What progress his Department has made on ...\n",
       "2         1  3.  What steps she is taking to ensure that il...\n",
       "3        19  15.  What additional investment the Government...\n",
       "4         7  11.  If he will commission research on the pot...\n",
       "...     ...                                                ...\n",
       "3513      4  I am grateful for this opportunity to raise in...\n",
       "3514      3  10.  What steps his Department has taken to he...\n",
       "3515      7  4.  What progress has been made on implementin...\n",
       "3516     14  3.  What diplomatic support the Government are...\n",
       "3517     11  5. What rights he plans to secure for UK citiz...\n",
       "\n",
       "[3518 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['transcript'].values\n",
    "Y = df['topic'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3528it [00:03, 1132.37it/s]                          \n"
     ]
    }
   ],
   "source": [
    "print('preprocessing data!!')\n",
    "#preprocessed_X = list(map(preprocess_text, X))\n",
    "preprocessed_X = parmap.map(preprocess_text, X, pm_pbar=True)\n",
    "tagged_X = [models.doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_X)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training doc2vec\n"
     ]
    }
   ],
   "source": [
    "print('training doc2vec')\n",
    "doc2vec_model = Doc2Vec(vector_size=100, window=3, workers=mp.cpu_count(), epochs=40)\n",
    "doc2vec_model.build_vocab(tagged_X)\n",
    "doc2vec_model.train(tagged_X, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
    "doc2vec_model.save('./models/doc2vec/doc2vec_15_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Input Data for Neural Net Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "input_Y = Y.reshape(-1,1)\n",
    "enc.fit(input_Y)\n",
    "input_Y = enc.transform(input_Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3528it [00:16, 220.19it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (2814, 100)\n",
      "y_train:  (2814, 21)\n",
      "X_test:  (704, 100)\n",
      "y_test:  (704, 21)\n"
     ]
    }
   ],
   "source": [
    "print('preparing inputs')\n",
    "\n",
    "def get_doc_vec(doc):\n",
    "    return doc2vec_model.infer_vector(doc.words)\n",
    "\n",
    "inputs = parmap.map(get_doc_vec, tagged_X, pm_pbar=True)\n",
    "\n",
    "# for x in tagged_X:\n",
    "#     topic_vec = doc2vec_model.infer_vector(x.words)\n",
    "#     inputs.append(topic_vec)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, input_Y, stratify=input_Y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(100)),\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(21, activation='softmax')\n",
    "    ])\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, name='categorical_crossentropy')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2814 samples, validate on 704 samples\n",
      "Epoch 1/200\n",
      "2814/2814 [==============================] - 1s 392us/sample - loss: 6.4206 - accuracy: 0.1386 - val_loss: 4.6627 - val_accuracy: 0.2642\n",
      "Epoch 2/200\n",
      "2814/2814 [==============================] - 0s 106us/sample - loss: 3.6473 - accuracy: 0.4165 - val_loss: 2.9234 - val_accuracy: 0.5057\n",
      "Epoch 3/200\n",
      "2814/2814 [==============================] - 0s 103us/sample - loss: 2.4602 - accuracy: 0.5590 - val_loss: 2.1783 - val_accuracy: 0.5980\n",
      "Epoch 4/200\n",
      "2814/2814 [==============================] - 0s 105us/sample - loss: 1.9712 - accuracy: 0.6215 - val_loss: 1.8942 - val_accuracy: 0.6250\n",
      "Epoch 5/200\n",
      "2814/2814 [==============================] - 0s 97us/sample - loss: 1.7676 - accuracy: 0.6496 - val_loss: 1.7759 - val_accuracy: 0.6236\n",
      "Epoch 6/200\n",
      "2814/2814 [==============================] - 0s 84us/sample - loss: 1.6672 - accuracy: 0.6596 - val_loss: 1.7019 - val_accuracy: 0.6534\n",
      "Epoch 7/200\n",
      "2814/2814 [==============================] - 0s 72us/sample - loss: 1.6100 - accuracy: 0.6638 - val_loss: 1.6631 - val_accuracy: 0.6520\n",
      "Epoch 8/200\n",
      "2814/2814 [==============================] - 0s 63us/sample - loss: 1.5637 - accuracy: 0.6763 - val_loss: 1.6202 - val_accuracy: 0.6577\n",
      "Epoch 9/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.5265 - accuracy: 0.6866 - val_loss: 1.6028 - val_accuracy: 0.6562\n",
      "Epoch 10/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.4965 - accuracy: 0.6851 - val_loss: 1.5766 - val_accuracy: 0.6378\n",
      "Epoch 11/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.4725 - accuracy: 0.6869 - val_loss: 1.5632 - val_accuracy: 0.6477\n",
      "Epoch 12/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.4453 - accuracy: 0.6930 - val_loss: 1.5327 - val_accuracy: 0.6406\n",
      "Epoch 13/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.4272 - accuracy: 0.6827 - val_loss: 1.5278 - val_accuracy: 0.6491\n",
      "Epoch 14/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.4032 - accuracy: 0.6958 - val_loss: 1.5073 - val_accuracy: 0.6591\n",
      "Epoch 15/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.3874 - accuracy: 0.6912 - val_loss: 1.4887 - val_accuracy: 0.6506\n",
      "Epoch 16/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.3714 - accuracy: 0.6962 - val_loss: 1.4748 - val_accuracy: 0.6548\n",
      "Epoch 17/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.3574 - accuracy: 0.6947 - val_loss: 1.4636 - val_accuracy: 0.6491\n",
      "Epoch 18/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.3406 - accuracy: 0.7001 - val_loss: 1.4671 - val_accuracy: 0.6534\n",
      "Epoch 19/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.3313 - accuracy: 0.7018 - val_loss: 1.4750 - val_accuracy: 0.6321\n",
      "Epoch 20/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.3190 - accuracy: 0.7075 - val_loss: 1.4407 - val_accuracy: 0.6506\n",
      "Epoch 21/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.3046 - accuracy: 0.7015 - val_loss: 1.4414 - val_accuracy: 0.6619\n",
      "Epoch 22/200\n",
      "2814/2814 [==============================] - 0s 63us/sample - loss: 1.2936 - accuracy: 0.7061 - val_loss: 1.4258 - val_accuracy: 0.6591\n",
      "Epoch 23/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2827 - accuracy: 0.7125 - val_loss: 1.4167 - val_accuracy: 0.6506\n",
      "Epoch 24/200\n",
      "2814/2814 [==============================] - 0s 57us/sample - loss: 1.2724 - accuracy: 0.7090 - val_loss: 1.4129 - val_accuracy: 0.6605\n",
      "Epoch 25/200\n",
      "2814/2814 [==============================] - 0s 58us/sample - loss: 1.2655 - accuracy: 0.7107 - val_loss: 1.4048 - val_accuracy: 0.6562\n",
      "Epoch 26/200\n",
      "2814/2814 [==============================] - 0s 61us/sample - loss: 1.2529 - accuracy: 0.7186 - val_loss: 1.3979 - val_accuracy: 0.6577\n",
      "Epoch 27/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2515 - accuracy: 0.7086 - val_loss: 1.4053 - val_accuracy: 0.6506\n",
      "Epoch 28/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2354 - accuracy: 0.7186 - val_loss: 1.3878 - val_accuracy: 0.6648\n",
      "Epoch 29/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2283 - accuracy: 0.7210 - val_loss: 1.3842 - val_accuracy: 0.6690\n",
      "Epoch 30/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2194 - accuracy: 0.7264 - val_loss: 1.3982 - val_accuracy: 0.6449\n",
      "Epoch 31/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2129 - accuracy: 0.7207 - val_loss: 1.3869 - val_accuracy: 0.6605\n",
      "Epoch 32/200\n",
      "2814/2814 [==============================] - 0s 59us/sample - loss: 1.2130 - accuracy: 0.7139 - val_loss: 1.3869 - val_accuracy: 0.6591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f31ab541ed0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_network()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=200, callbacks=[callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./models/doc2vec/classifier_15_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
