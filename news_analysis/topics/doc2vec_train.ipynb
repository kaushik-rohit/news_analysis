{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing as mp\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_index_to_name_map = {\n",
    "    0: 'Agriculture, animals, food and rural affairs',\n",
    "    1: 'Asylum, immigration and nationality',\n",
    "    2: 'Business, industry and consumers',\n",
    "    3: 'Communities and families',\n",
    "    4: 'Crime, civil law, justice and rights',\n",
    "    5: 'Culture, media and sport',\n",
    "    6: 'Defence',\n",
    "    7: 'Economy and finance',\n",
    "    8: 'Education',\n",
    "    9: 'Employment and training',\n",
    "    10: 'Energy and environment',\n",
    "    11: 'European Union',\n",
    "    12: 'Health services and medicine',\n",
    "    13: 'Housing and planning',\n",
    "    14: 'International affairs',\n",
    "    15: 'Parliament, government and politics',\n",
    "    16: 'Science and technology',\n",
    "    17: 'Social security and pensions',\n",
    "    18: 'Social services',\n",
    "    19: 'Transport',\n",
    "    20: 'Others'\n",
    "}\n",
    "topics_name_to_index_map = {y:x for x,y in topics_index_to_name_map.items()}\n",
    "\n",
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "def remove_non_nouns(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    filter_tokens = [t[0] for t in tags if t[1] == \"NN\" or t[1] == \"VB\"]\n",
    "    return ' '.join(filter_tokens)\n",
    "\n",
    "\n",
    "def preprocess_text_for_lda(text):\n",
    "    LDA_FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, LDA_FILTERS)\n",
    "\n",
    "def preprocess(topic):\n",
    "    ret = []\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    if '|' in topic:\n",
    "        topics = topic.split('|')\n",
    "        t = topics[0]\n",
    "        t = t.strip()\n",
    "        return topics_name_to_index_map[t]\n",
    "        \n",
    "    return topics_name_to_index_map[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing data!!\n"
     ]
    }
   ],
   "source": [
    "print('preparing data!!')\n",
    "df1 = pd.read_csv('./data/2011_speech.csv')\n",
    "df2 = pd.read_csv('./data/2012_speech.csv')\n",
    "df3 = pd.read_csv('./data/2013_speech.csv')\n",
    "df = pd.concat([df2, df3])\n",
    "df = df.drop(['date'], axis=1)\n",
    "df = df.drop(df[df.topic == 'admin'].index)\n",
    "df = df.drop(df[df.transcript.str.split().map(len) < 10].index)\n",
    "df['topic'] = df.apply(lambda row: preprocess(row['topic']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     11690\n",
       "15    11319\n",
       "20    10631\n",
       "4      8794\n",
       "14     6868\n",
       "9      5914\n",
       "12     5729\n",
       "3      5577\n",
       "2      4576\n",
       "19     4438\n",
       "11     3868\n",
       "6      3762\n",
       "10     3753\n",
       "8      3425\n",
       "5      3392\n",
       "0      2183\n",
       "13     1334\n",
       "1      1204\n",
       "17     1191\n",
       "16      549\n",
       "18      548\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>I welcome my hon. Friend to his new position. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>I hear Opposition Members shouting out about w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Would the Minister not rather be understanding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Exactly. Amazingly, the questionnaire process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>I very much doubt it; we can but hope. There a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100740</th>\n",
       "      <td>14</td>\n",
       "      <td>The hon. Gentleman makes an excellent suggesti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100741</th>\n",
       "      <td>14</td>\n",
       "      <td>I can only ask why, then, did we not give Hans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100742</th>\n",
       "      <td>19</td>\n",
       "      <td>Businesses in Slough tell me that they have in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100743</th>\n",
       "      <td>3</td>\n",
       "      <td>It is a pleasure to follow such a wise speech ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100744</th>\n",
       "      <td>7</td>\n",
       "      <td>As I have said, when the Bill is passed, the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100745 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic                                         transcript\n",
       "0          19  I welcome my hon. Friend to his new position. ...\n",
       "1          11  I hear Opposition Members shouting out about w...\n",
       "2           7  Would the Minister not rather be understanding...\n",
       "3           9  Exactly. Amazingly, the questionnaire process ...\n",
       "4           7  I very much doubt it; we can but hope. There a...\n",
       "...       ...                                                ...\n",
       "100740     14  The hon. Gentleman makes an excellent suggesti...\n",
       "100741     14  I can only ask why, then, did we not give Hans...\n",
       "100742     19  Businesses in Slough tell me that they have in...\n",
       "100743      3  It is a pleasure to follow such a wise speech ...\n",
       "100744      7  As I have said, when the Bill is passed, the s...\n",
       "\n",
       "[100745 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['transcript'].values\n",
    "Y = df['topic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing data!!\n"
     ]
    }
   ],
   "source": [
    "print('preprocessing data!!')\n",
    "preprocessed_X = list(map(preprocess_text_for_lda, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_X = [models.doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training doc2vec\n"
     ]
    }
   ],
   "source": [
    "print('training doc2vec')\n",
    "doc2vec_model = Doc2Vec(vector_size=300, min_count=2, window=3, workers=mp.cpu_count(), epochs=40)\n",
    "doc2vec_model.build_vocab(tagged_X)\n",
    "doc2vec_model.train(tagged_X, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model.save('doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "Y = Y.reshape(-1,1)\n",
    "enc.fit(Y)\n",
    "Y = enc.transform(Y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# one_hot = MultiLabelBinarizer()\n",
    "# one_hot.fit_transform(Y)\n",
    "# Y = one_hot.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing inputs\n",
      "X_train:  (80596, 300)\n",
      "y_train:  (80596, 21)\n",
      "X_test:  (20149, 300)\n",
      "y_test:  (20149, 21)\n"
     ]
    }
   ],
   "source": [
    "print('preparing inputs')\n",
    "inputs = []\n",
    "for x in tagged_X:\n",
    "    topic_vec = doc2vec_model.infer_vector(x.words)\n",
    "    inputs.append(topic_vec)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, Y, stratify=Y, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(300)),\n",
    "        tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)),\n",
    "        tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)),\n",
    "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.001)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(21, activation='softmax')\n",
    "    ])\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, name='categorical_crossentropy')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80596 samples, validate on 20149 samples\n",
      "Epoch 1/200\n",
      "80596/80596 [==============================] - 14s 176us/sample - loss: 2.3662 - accuracy: 0.4071 - val_loss: 2.1124 - val_accuracy: 0.4389\n",
      "Epoch 2/200\n",
      "80596/80596 [==============================] - 15s 189us/sample - loss: 2.0295 - accuracy: 0.4593 - val_loss: 2.0042 - val_accuracy: 0.4589\n",
      "Epoch 3/200\n",
      "80596/80596 [==============================] - 17s 207us/sample - loss: 1.9318 - accuracy: 0.4802 - val_loss: 1.9943 - val_accuracy: 0.4624\n",
      "Epoch 4/200\n",
      "80596/80596 [==============================] - 17s 206us/sample - loss: 1.8729 - accuracy: 0.4954 - val_loss: 1.9354 - val_accuracy: 0.4742\n",
      "Epoch 5/200\n",
      "80596/80596 [==============================] - 16s 196us/sample - loss: 1.8323 - accuracy: 0.5089 - val_loss: 1.9584 - val_accuracy: 0.4744\n",
      "Epoch 6/200\n",
      "80596/80596 [==============================] - 16s 202us/sample - loss: 1.8081 - accuracy: 0.5169 - val_loss: 1.9558 - val_accuracy: 0.4757\n",
      "Epoch 7/200\n",
      "80596/80596 [==============================] - 17s 205us/sample - loss: 1.7874 - accuracy: 0.5260 - val_loss: 1.9471 - val_accuracy: 0.4815\n",
      "Epoch 8/200\n",
      "80596/80596 [==============================] - 17s 213us/sample - loss: 1.7693 - accuracy: 0.5316 - val_loss: 1.9440 - val_accuracy: 0.4825\n",
      "Epoch 9/200\n",
      "80596/80596 [==============================] - 18s 226us/sample - loss: 1.7569 - accuracy: 0.5358 - val_loss: 1.9625 - val_accuracy: 0.4818\n",
      "Epoch 10/200\n",
      "80596/80596 [==============================] - 18s 218us/sample - loss: 1.7464 - accuracy: 0.5390 - val_loss: 1.9539 - val_accuracy: 0.4799\n",
      "Epoch 11/200\n",
      "80596/80596 [==============================] - 18s 220us/sample - loss: 1.7367 - accuracy: 0.5440 - val_loss: 1.9809 - val_accuracy: 0.4789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5bf0700cd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_network()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=200, callbacks=[callback], validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./topics_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
