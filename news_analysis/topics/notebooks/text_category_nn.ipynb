{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric, stem_text\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Constituency ID</th>\n",
       "      <th>full name</th>\n",
       "      <th>PANO</th>\n",
       "      <th>Constituency Name</th>\n",
       "      <th>Party abbreviation</th>\n",
       "      <th>conShare</th>\n",
       "      <th>conShare2</th>\n",
       "      <th>conShare3</th>\n",
       "      <th>bill161</th>\n",
       "      <th>leave</th>\n",
       "      <th>party_old</th>\n",
       "      <th>ref</th>\n",
       "      <th>ref_dummy</th>\n",
       "      <th>party</th>\n",
       "      <th>old_party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E14000530</td>\n",
       "      <td>Gerald Howarth</td>\n",
       "      <td>7</td>\n",
       "      <td>Aldershot</td>\n",
       "      <td>Con</td>\n",
       "      <td>50.59</td>\n",
       "      <td>73.403947</td>\n",
       "      <td>73.403947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E14000531</td>\n",
       "      <td>Wendy Morton</td>\n",
       "      <td>8</td>\n",
       "      <td>Aldridge-Brownhills</td>\n",
       "      <td>Con</td>\n",
       "      <td>52.05</td>\n",
       "      <td>69.940876</td>\n",
       "      <td>69.940876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677963</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E14000532</td>\n",
       "      <td>Graham Brady</td>\n",
       "      <td>9</td>\n",
       "      <td>Altrincham and Sale West</td>\n",
       "      <td>Con</td>\n",
       "      <td>52.99</td>\n",
       "      <td>66.503514</td>\n",
       "      <td>66.503514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.385878</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E14000533</td>\n",
       "      <td>Nigel Mills</td>\n",
       "      <td>11</td>\n",
       "      <td>Amber Valley</td>\n",
       "      <td>Con</td>\n",
       "      <td>43.98</td>\n",
       "      <td>55.840528</td>\n",
       "      <td>55.840528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652991</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E14000534</td>\n",
       "      <td>Nick Herbert</td>\n",
       "      <td>18</td>\n",
       "      <td>Arundel and South Downs</td>\n",
       "      <td>Con</td>\n",
       "      <td>60.79</td>\n",
       "      <td>84.442284</td>\n",
       "      <td>84.442284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.497011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>W07000076</td>\n",
       "      <td>Wayne David</td>\n",
       "      <td>114</td>\n",
       "      <td>Caerphilly</td>\n",
       "      <td>Lab</td>\n",
       "      <td>16.59</td>\n",
       "      <td>27.223499</td>\n",
       "      <td>27.223499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.551360</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>W07000077</td>\n",
       "      <td>Chris Evans</td>\n",
       "      <td>336</td>\n",
       "      <td>Islwyn</td>\n",
       "      <td>Lab</td>\n",
       "      <td>15.16</td>\n",
       "      <td>23.639482</td>\n",
       "      <td>23.639482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>W07000078</td>\n",
       "      <td>Alun Cairns</td>\n",
       "      <td>589</td>\n",
       "      <td>Vale Of Glamorgan</td>\n",
       "      <td>Con</td>\n",
       "      <td>46.02</td>\n",
       "      <td>58.527280</td>\n",
       "      <td>58.527280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525507</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>W07000079</td>\n",
       "      <td>Kevin Brennan</td>\n",
       "      <td>129</td>\n",
       "      <td>Cardiff West</td>\n",
       "      <td>Lab</td>\n",
       "      <td>25.15</td>\n",
       "      <td>38.221884</td>\n",
       "      <td>38.221884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438226</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>W07000080</td>\n",
       "      <td>Stephen Doughty</td>\n",
       "      <td>128</td>\n",
       "      <td>Cardiff South and Penarth</td>\n",
       "      <td>Lab</td>\n",
       "      <td>26.81</td>\n",
       "      <td>38.525650</td>\n",
       "      <td>38.525650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Constituency ID        full name  PANO          Constituency Name  \\\n",
       "0         E14000530   Gerald Howarth     7                  Aldershot   \n",
       "1         E14000531     Wendy Morton     8        Aldridge-Brownhills   \n",
       "2         E14000532     Graham Brady     9   Altrincham and Sale West   \n",
       "3         E14000533      Nigel Mills    11               Amber Valley   \n",
       "4         E14000534     Nick Herbert    18    Arundel and South Downs   \n",
       "..              ...              ...   ...                        ...   \n",
       "655       W07000076      Wayne David   114                 Caerphilly   \n",
       "656       W07000077      Chris Evans   336                     Islwyn   \n",
       "657       W07000078      Alun Cairns   589          Vale Of Glamorgan   \n",
       "658       W07000079    Kevin Brennan   129               Cardiff West   \n",
       "659       W07000080  Stephen Doughty   128  Cardiff South and Penarth   \n",
       "\n",
       "    Party abbreviation  conShare  conShare2  conShare3  bill161  leave  \\\n",
       "0                  Con     50.59  73.403947  73.403947      1.0    1.0   \n",
       "1                  Con     52.05  69.940876  69.940876      1.0    0.0   \n",
       "2                  Con     52.99  66.503514  66.503514      1.0    1.0   \n",
       "3                  Con     43.98  55.840528  55.840528      1.0    1.0   \n",
       "4                  Con     60.79  84.442284  84.442284      NaN    0.0   \n",
       "..                 ...       ...        ...        ...      ...    ...   \n",
       "655                Lab     16.59  27.223499  27.223499      1.0    0.0   \n",
       "656                Lab     15.16  23.639482  23.639482      1.0    0.0   \n",
       "657                Con     46.02  58.527280  58.527280      1.0    0.0   \n",
       "658                Lab     25.15  38.221884  38.221884      0.0    0.0   \n",
       "659                Lab     26.81  38.525650  38.525650      0.0    0.0   \n",
       "\n",
       "     party_old       ref  ref_dummy  party  old_party  \n",
       "0          1.0  0.578978          1    1.0        1.0  \n",
       "1          1.0  0.677963          1    0.0        0.0  \n",
       "2          1.0  0.385878          0    1.0        1.0  \n",
       "3          1.0  0.652991          1    1.0        1.0  \n",
       "4          1.0  0.497011          0    0.0        0.0  \n",
       "..         ...       ...        ...    ...        ...  \n",
       "655        0.0  0.551360          1    0.0        NaN  \n",
       "656        0.0  0.589399          1    0.0        NaN  \n",
       "657        1.0  0.525507          1    0.0        0.0  \n",
       "658        0.0  0.438226          0    0.0        NaN  \n",
       "659        0.0  0.428172          0    0.0        NaN  \n",
       "\n",
       "[660 rows x 15 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_file = pd.read_csv('brexit_full_updated3.csv')\n",
    "vote_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians_party = {}\n",
    "politicians = vote_file['full name'].unique()\n",
    "for index, row in vote_file.iterrows():\n",
    "    politicians_party[row['full name']] = row['party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Topic</th>\n",
       "      <th>transcript</th>\n",
       "      <th>party2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18469</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>Mr Simon Burns (Chelmsford) (Con)</td>\n",
       "      <td>Simon Burns</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>admin</td>\n",
       "      <td>I beg to move,  That an humble Address be pres...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18470</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>Mrs Sheryll Murray (South East Cornwall) (Con)</td>\n",
       "      <td>Sheryll Murray</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>admin</td>\n",
       "      <td>It is an honour to be invited to second this H...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18471</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>Ms Harriet Harman (Camberwell and Peckham) (Lab)</td>\n",
       "      <td>Harriet Harman</td>\n",
       "      <td>Labour</td>\n",
       "      <td>admin</td>\n",
       "      <td>I am sure the whole House will want to pay tri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18472</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>The Prime Minister (Mr David Cameron)</td>\n",
       "      <td>David Cameron</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>admin</td>\n",
       "      <td>As we meet today, we should start, as the righ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18473</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>Mr David Winnick (Walsall North) (Lab)</td>\n",
       "      <td>David Winnick</td>\n",
       "      <td>Labour</td>\n",
       "      <td>admin</td>\n",
       "      <td>The right hon. Gentleman is talking about â€œone...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                           speaker  \\\n",
       "18469 2015-05-27                 Mr Simon Burns (Chelmsford) (Con)   \n",
       "18470 2015-05-27    Mrs Sheryll Murray (South East Cornwall) (Con)   \n",
       "18471 2015-05-27  Ms Harriet Harman (Camberwell and Peckham) (Lab)   \n",
       "18472 2015-05-27             The Prime Minister (Mr David Cameron)   \n",
       "18473 2015-05-27            Mr David Winnick (Walsall North) (Lab)   \n",
       "\n",
       "                 name         Party  Topic  \\\n",
       "18469     Simon Burns  Conservative  admin   \n",
       "18470  Sheryll Murray  Conservative  admin   \n",
       "18471  Harriet Harman        Labour  admin   \n",
       "18472   David Cameron  Conservative  admin   \n",
       "18473   David Winnick        Labour  admin   \n",
       "\n",
       "                                              transcript  party2  \n",
       "18469  I beg to move,  That an humble Address be pres...     0.0  \n",
       "18470  It is an honour to be invited to second this H...     1.0  \n",
       "18471  I am sure the whole House will want to pay tri...     0.0  \n",
       "18472  As we meet today, we should start, as the righ...     0.0  \n",
       "18473  The right hon. Gentleman is talking about â€œone...     0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('2015_commons.csv')\n",
    "df2 = pd.read_csv('2016_commons.csv')\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.drop(['Government'], axis=1)\n",
    "df = df.loc[(df['Party'] == 'Conservative') | (df['Party'] == 'Labour')]\n",
    "df = df.loc[df['Name'].isin(politicians)]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "mask = (df['Date'] > '2015-5-1') & (df['Date'] <= '2016-6-30')\n",
    "df = df.loc[mask]\n",
    "df['party2'] = df['Name'].apply(lambda x: politicians_party[x])\n",
    "# df = df.loc[df['Topic'] == 'European Union']\n",
    "cols = df.columns\n",
    "cols = ['date', 'speaker', 'name', 'Party', 'Topic', 'transcript', 'party2']\n",
    "df.columns = cols\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    party = row['Party']\n",
    "    party2 = row['party2']\n",
    "    if party == 'Conservative' and party2 == 1:\n",
    "        X.append(row['transcript'])\n",
    "        Y.append(0)\n",
    "    if party == 'Labour' and party2 == 0:\n",
    "        X.append(row['transcript'])\n",
    "        Y.append(1)\n",
    "        \n",
    "    if party == 'Conservative' and party2 == 0:\n",
    "        X_test.append(row['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X, Y))\n",
    "random.shuffle(c)\n",
    "X, Y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30592it [00:01, 21236.23it/s]            \n"
     ]
    }
   ],
   "source": [
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, FILTERS)\n",
    "\n",
    "\n",
    "preprocessed_X = parmap.map(preprocess_text, X, pm_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, vector_size=100, window=3, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(100)),\n",
    "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(1, activation='softmax')\n",
    "    ])\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0, name='binary_crossentropy')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30592it [00:02, 11235.11it/s]                          \n"
     ]
    }
   ],
   "source": [
    "def get_doc_vec(doc):\n",
    "    return model.infer_vector(doc.words)\n",
    "\n",
    "X_vec = parmap.map(get_doc_vec, documents, pm_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30551, 100)\n"
     ]
    }
   ],
   "source": [
    "X_vec = np.array(X_vec)\n",
    "Y = np.array(Y)\n",
    "print(X_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Epoch 1/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 2.2847 - accuracy: 0.5547\n",
      "Epoch 2/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6874 - accuracy: 0.5547\n",
      "Epoch 3/25\n",
      "478/478 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5547\n",
      "Epoch 4/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5547\n",
      "Epoch 5/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 6/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 7/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 8/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5547\n",
      "Epoch 9/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 10/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 11/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 12/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5547\n",
      "Epoch 13/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 14/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6873 - accuracy: 0.5547\n",
      "Epoch 15/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 16/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 17/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 18/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 19/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 20/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 21/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 22/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 23/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 24/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 25/25\n",
      "478/478 [==============================] - 1s 1ms/step - loss: 0.6872 - accuracy: 0.5547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f57a1fd6f10>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = build_network()\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# class_weights = class_weight.compute_class_weight('balanced', np.unique(Y), Y)\n",
    "classifier.fit(X_vec, Y, batch_size=64, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26496it [00:01, 19875.87it/s]            \n"
     ]
    }
   ],
   "source": [
    "preprocessed_X_test = parmap.map(preprocess_text, X_test, pm_pbar=True)\n",
    "tagged_X_test = [models.doc2vec.TaggedDocument(doc, [i]) for i, doc in enumerate(preprocessed_X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26496it [00:02, 13162.04it/s]                           \n"
     ]
    }
   ],
   "source": [
    "inputs = parmap.map(get_doc_vec, tagged_X_test, pm_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
