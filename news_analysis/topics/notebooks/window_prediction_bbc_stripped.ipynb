{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/econ/lib/python3.7/site-packages/dask/dataframe/utils.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing as mp\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import spatial\n",
    "import parmap\n",
    "import os\n",
    "import swifter\n",
    "from tqdm import tqdm\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_index_to_name_map = {\n",
    "    0: 'Agriculture, animals, food and rural affairs',\n",
    "    1: 'Asylum, immigration and nationality',\n",
    "    2: 'Business, industry and consumers',\n",
    "    3: 'Communities and families',\n",
    "    4: 'Crime, civil law, justice and rights',\n",
    "    5: 'Culture, media and sport',\n",
    "    6: 'Defence',\n",
    "    7: 'Economy and finance',\n",
    "    8: 'Education',\n",
    "    9: 'Employment and training',\n",
    "    10: 'Energy and environment',\n",
    "    11: 'European Union',\n",
    "    12: 'Health services and medicine',\n",
    "    13: 'Housing and planning',\n",
    "    14: 'International affairs',\n",
    "    15: 'Parliament, government and politics',\n",
    "    16: 'Science and technology',\n",
    "    17: 'Social security and pensions',\n",
    "    18: 'Social services',\n",
    "    19: 'Transport',\n",
    "    20: 'Others'\n",
    "}\n",
    "topics_name_to_index_map = {y:x for x,y in topics_index_to_name_map.items()}\n",
    "\n",
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, FILTERS)\n",
    "\n",
    "def preprocess(topic):\n",
    "    ret = []\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    if '|' in topic:\n",
    "        topics = topic.split('|')\n",
    "        t = topics[0]\n",
    "        t = t.strip()\n",
    "        return topics_name_to_index_map[t]\n",
    "        \n",
    "    return topics_name_to_index_map[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./bert_partitions_54_{}.csv'.format(year))\n",
    "# df = df.loc[df['Program Name'].isin(['BBC News at One', 'BBC News at Ten', 'BBC News at Six'])].reset_index(drop=True)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_model = Doc2Vec.load('../models/doc2vec/doc2vec_news_{}_no_Others'.format(2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Date</th>\n",
       "      <th>Program Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>partitioned_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>02:05</td>\n",
       "      <td>235 mins</td>\n",
       "      <td>but also gathering storm clouds, some further ...</td>\n",
       "      <td>[p] but also gathering storm clouds, some furt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>13:00</td>\n",
       "      <td>15 mins</td>\n",
       "      <td>CRIMEWATCH ROADSHOW LIVE AA0252740VA01NAT BRDO...</td>\n",
       "      <td>[p] CRIMEWATCH ROADSHOW LIVE AA0252740VA01NAT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>17:50</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>You’re lying! At least this is the real thing....</td>\n",
       "      <td>[p] You’re lying! At least this is the real th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>18:00</td>\n",
       "      <td>5 mins</td>\n",
       "      <td>at times flawed. It is a test of temperament a...</td>\n",
       "      <td>[p] at times flawed. It is a test of temperame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-06-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>22:10</td>\n",
       "      <td>20 mins</td>\n",
       "      <td># Ochi zhguchie i... # 0h! You have to say tha...</td>\n",
       "      <td>[p] # Ochi zhguchie i... # 0h! You have to say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>13:30</td>\n",
       "      <td>15 mins</td>\n",
       "      <td>The researchers say whales and dolphins are am...</td>\n",
       "      <td>[p] The researchers say whales and dolphins ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>BBC News 24</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>BBC News at Six</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 mins</td>\n",
       "      <td>BBC? I was extremely happily mnning the Royal ...</td>\n",
       "      <td>[p] BBC? I was extremely happily mnning the Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 mins</td>\n",
       "      <td>Another high street flooded thanks Another hig...</td>\n",
       "      <td>[p] Another high street flooded thanks Another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>BBC News at Ten</td>\n",
       "      <td>22:00</td>\n",
       "      <td>30 mins</td>\n",
       "      <td>Now back at home, she’s speaking for the first...</td>\n",
       "      <td>[p] Now back at home, she’s speaking for the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>BBC1 London</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>22:30</td>\n",
       "      <td>15 mins</td>\n",
       "      <td>A year later, many areas of the city have inde...</td>\n",
       "      <td>[p] A year later, many areas of the city have ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2125 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Source       Date     Program Name   Time  Duration  \\\n",
       "0     BBC1 London 2018-06-02         BBC News  02:05  235 mins   \n",
       "1     BBC1 London 2018-06-02         BBC News  13:00   15 mins   \n",
       "2     BBC1 London 2018-06-02         BBC News  17:50   10 mins   \n",
       "3     BBC1 London 2018-06-02  BBC London News  18:00    5 mins   \n",
       "4     BBC1 London 2018-06-02         BBC News  22:10   20 mins   \n",
       "...           ...        ...              ...    ...       ...   \n",
       "2120  BBC1 London 2018-01-31  BBC London News  13:30   15 mins   \n",
       "2121  BBC News 24 2018-01-31  BBC News at Six  18:00   30 mins   \n",
       "2122  BBC1 London 2018-01-31  BBC London News  18:30   30 mins   \n",
       "2123  BBC1 London 2018-01-31  BBC News at Ten  22:00   30 mins   \n",
       "2124  BBC1 London 2018-01-31  BBC London News  22:30   15 mins   \n",
       "\n",
       "                                             Transcript  \\\n",
       "0     but also gathering storm clouds, some further ...   \n",
       "1     CRIMEWATCH ROADSHOW LIVE AA0252740VA01NAT BRDO...   \n",
       "2     You’re lying! At least this is the real thing....   \n",
       "3     at times flawed. It is a test of temperament a...   \n",
       "4     # Ochi zhguchie i... # 0h! You have to say tha...   \n",
       "...                                                 ...   \n",
       "2120  The researchers say whales and dolphins are am...   \n",
       "2121  BBC? I was extremely happily mnning the Royal ...   \n",
       "2122  Another high street flooded thanks Another hig...   \n",
       "2123  Now back at home, she’s speaking for the first...   \n",
       "2124  A year later, many areas of the city have inde...   \n",
       "\n",
       "                                 partitioned_transcript  \n",
       "0     [p] but also gathering storm clouds, some furt...  \n",
       "1     [p] CRIMEWATCH ROADSHOW LIVE AA0252740VA01NAT ...  \n",
       "2     [p] You’re lying! At least this is the real th...  \n",
       "3     [p] at times flawed. It is a test of temperame...  \n",
       "4     [p] # Ochi zhguchie i... # 0h! You have to say...  \n",
       "...                                                 ...  \n",
       "2120  [p] The researchers say whales and dolphins ar...  \n",
       "2121  [p] BBC? I was extremely happily mnning the Ro...  \n",
       "2122  [p] Another high street flooded thanks Another...  \n",
       "2123  [p] Now back at home, she’s speaking for the f...  \n",
       "2124  [p] A year later, many areas of the city have ...  \n",
       "\n",
       "[2125 rows x 7 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = []\n",
    "for index, row in df.iterrows():\n",
    "    partition_string = row['partitioned_transcript']\n",
    "    partition_date = row['Date']\n",
    "    partition_source = row['Program Name']\n",
    "    all_partitions = partition_string.split('\\n')\n",
    "    for partition in all_partitions:\n",
    "        t = None\n",
    "        if partition.startswith('[p]') and partition.endswith('[/p]'):\n",
    "            t = 'p'\n",
    "        else:\n",
    "            t = 's'\n",
    "        partitions.append((index, partition_date, partition_source, partition[3:-4], t))\n",
    "partition_df = pd.DataFrame(partitions, columns=['partition_id', 'date', 'source', 'transcript', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (partition_df['date'] >= '2018-7-1') & (partition_df['date'] <= '2018-12-31')\n",
    "partition_df = partition_df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition_id</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>transcript</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>and she paid a price for it. # ..Love you... ...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>Undercover: Britain’s Immigration Secrets. On...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>Put your thumb vertically above her and make ...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>One and two and three. One, two, three. Yeah,...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-09-02</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>As we step into the first weekend in Septembe...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225253</th>\n",
       "      <td>2090</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>In Lapland, a group of disappointed children ...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225254</th>\n",
       "      <td>2090</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>APPLAUSE And on her first day working at a Ch...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225255</th>\n",
       "      <td>2090</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>Not quite up there with The LastJedi, but a n...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225256</th>\n",
       "      <td>2090</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>Please welcome Joe Wilkinson!</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225257</th>\n",
       "      <td>2090</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>BBC London News</td>\n",
       "      <td>CHEERING AND APPLAUSE And with Paul tonight i...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122907 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        partition_id       date           source  \\\n",
       "0                  0 2017-09-02         BBC News   \n",
       "1                  0 2017-09-02         BBC News   \n",
       "2                  0 2017-09-02         BBC News   \n",
       "3                  0 2017-09-02         BBC News   \n",
       "4                  0 2017-09-02         BBC News   \n",
       "...              ...        ...              ...   \n",
       "225253          2090 2017-12-18  BBC London News   \n",
       "225254          2090 2017-12-18  BBC London News   \n",
       "225255          2090 2017-12-18  BBC London News   \n",
       "225256          2090 2017-12-18  BBC London News   \n",
       "225257          2090 2017-12-18  BBC London News   \n",
       "\n",
       "                                               transcript type  \n",
       "0        and she paid a price for it. # ..Love you... ...    p  \n",
       "1        Undercover: Britain’s Immigration Secrets. On...    s  \n",
       "2        Put your thumb vertically above her and make ...    p  \n",
       "3        One and two and three. One, two, three. Yeah,...    s  \n",
       "4        As we step into the first weekend in Septembe...    p  \n",
       "...                                                   ...  ...  \n",
       "225253   In Lapland, a group of disappointed children ...    p  \n",
       "225254   APPLAUSE And on her first day working at a Ch...    p  \n",
       "225255   Not quite up there with The LastJedi, but a n...    p  \n",
       "225256                      Please welcome Joe Wilkinson!    s  \n",
       "225257   CHEERING AND APPLAUSE And with Paul tonight i...    p  \n",
       "\n",
       "[122907 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ec85543c5a4742be52367451fd9e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=41616.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "partition_df['vector'] = partition_df.swifter.apply(lambda x: doc2vec_model.infer_vector(preprocess_text(x['transcript'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pd.read_csv('../data/news_predictions/news_{}_predictions.csv'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.dropna(subset=['transcript'])\n",
    "articles = articles.loc[articles.top1_topic != 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.drop(['Unnamed: 0'], axis=1)\n",
    "articles = articles.loc[articles.month.isin([1,2,3,4,5,6])]\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = []\n",
    "transcripts = articles.transcript.values\n",
    "\n",
    "preprocessed_transcripts = parmap.map(preprocess_text, transcripts, pm_pbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_transcripts = parmap.map(doc2vec_model.infer_vector, preprocessed_transcripts, pm_pbar=True)\n",
    "articles['vector'] = vector_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del preprocessed_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "articles['date'] = articles.apply(lambda x: datetime.date(x.year, x.month, x.day), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import datetime, timedelta\n",
    "from semantic_text_similarity.models import WebBertSimilarity\n",
    "web_model = WebBertSimilarity(device='cpu', batch_size=10) #defaults to GPU prediction\n",
    "\n",
    "def predict(partition):\n",
    "    dt = partition.date\n",
    "    start_dt = dt - timedelta(days=2)\n",
    "    end_dt = dt + timedelta(days=2)\n",
    "    articles_window = articles.loc[(articles['date'] >= start_dt) & (articles['date'] <= end_dt)]\n",
    "    print(len(articles_window))\n",
    "    partition_vector = np.array(partition.vector)\n",
    "    partition_vector = partition_vector.reshape(1, 100)\n",
    "    articles_vector = articles_window.vector.values\n",
    "    vec = [articles_vector[i] for i in range(len(articles_vector))]\n",
    "    vec = np.array(vec)\n",
    "    sim = cosine_similarity(partition_vector, vec)\n",
    "    max_index = np.argmax(sim)\n",
    "    \n",
    "    return articles_window.iloc[max_index]['top1_topic']\n",
    "\n",
    "def predict_with_bert(partition):\n",
    "    dt = partition.date\n",
    "    start_dt = dt - timedelta(days=2)\n",
    "    end_dt = dt + timedelta(days=2)\n",
    "    articles_window = articles.loc[(articles['date'] >= start_dt) & (articles['date'] <= end_dt)]\n",
    "    partition_transcript = np.array(partition.transcript)\n",
    "    articles_transcript = articles_window.transcript.values\n",
    "    input_data = [(partition_transcript, a) for a in articles_transcript]\n",
    "    print(input_data[0])\n",
    "    sim = web_model.predict(input_data)\n",
    "    max_index = np.argmax(sim)\n",
    "    \n",
    "    return articles_window.iloc[max_index]['top1_topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(partition_df.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df.iloc[4].transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for index, row in tqdm(partition_df.iterrows(), total=len(partition_df)):\n",
    "    preds.append(predict(row))\n",
    "    \n",
    "partition_df['prediction'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df.to_csv('./partitions_Jul-Dec_54_{}.csv'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
