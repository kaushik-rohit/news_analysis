{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import models, corpora\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text, strip_non_alphanum, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import strip_short, strip_numeric\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import multiprocessing as mp\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import parmap\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_index_to_name_map = {\n",
    "    0: 'Agriculture, animals, food and rural affairs',\n",
    "    1: 'Asylum, immigration and nationality',\n",
    "    2: 'Business, industry and consumers',\n",
    "    3: 'Communities and families',\n",
    "    4: 'Crime, civil law, justice and rights',\n",
    "    5: 'Culture, media and sport',\n",
    "    6: 'Defence',\n",
    "    7: 'Economy and finance',\n",
    "    8: 'Education',\n",
    "    9: 'Employment and training',\n",
    "    10: 'Energy and environment',\n",
    "    11: 'European Union',\n",
    "    12: 'Health services and medicine',\n",
    "    13: 'Housing and planning',\n",
    "    14: 'International affairs',\n",
    "    15: 'Parliament, government and politics',\n",
    "    16: 'Science and technology',\n",
    "    17: 'Social security and pensions',\n",
    "    18: 'Social services',\n",
    "    19: 'Transport',\n",
    "    20: 'Others'\n",
    "}\n",
    "topics_name_to_index_map = {y:x for x,y in topics_index_to_name_map.items()}\n",
    "\n",
    "def strip_short2(text):\n",
    "    return strip_short(text, minsize=4)\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_tags, strip_punctuation,\n",
    "                   strip_non_alphanum, strip_numeric, strip_short2]\n",
    "    return preprocess_string(text, FILTERS)\n",
    "\n",
    "def preprocess(topic):\n",
    "    ret = []\n",
    "    topic = topic.strip()\n",
    "    \n",
    "    if '|' in topic:\n",
    "        topics = topic.split('|')\n",
    "        t = topics[0]\n",
    "        t = t.strip()\n",
    "        return topics_name_to_index_map[t]\n",
    "        \n",
    "    return topics_name_to_index_map[topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_id = 54\n",
    "year = 2016\n",
    "excluding = '_no_Others'\n",
    "years = [2016]\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    df_list.append(pd.read_csv('../data/partitions/bert_partitions_{}_{}.csv'.format(bbc_id, year)))\n",
    "    \n",
    "transcripts = pd.concat(df_list)\n",
    "transcripts = transcripts.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = transcripts.loc[(transcripts.Date.str.contains('may')) | (transcripts.Date.str.contains('apr'))]\n",
    "# program_names = ['BBC News at One', 'BBC News at Six', 'BBC News at Ten']\n",
    "# transcripts = transcripts.loc[transcripts[\"Program Name\"].isin(program_names)]\n",
    "# transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts = pd.read_csv('../data/partitions/bert_partitions_{}_{}.csv'.format(bbc_id, year))\n",
    "# transcripts = transcripts.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts = transcripts.dropna(subset=['Transcript', 'partitioned_transcript'])\n",
    "# transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = []\n",
    "for index, row in transcripts.iterrows():\n",
    "    partition_string = row['partitioned_transcript']\n",
    "    partition_date = row['Date']\n",
    "    all_partitions = partition_string.split('\\n---------------------\\n')\n",
    "    for partition in all_partitions:\n",
    "        partitions.append((index, partition_date, partition))\n",
    "partition_df = pd.DataFrame(partitions, columns=['partition_id', 'date', 'transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition_df = pd.read_csv('./data/partitions/ibm_partition_2015_July_19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition_id</th>\n",
       "      <th>date</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4-jun-2016</td>\n",
       "      <td>we would have seen during this weekend and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4-jun-2016</td>\n",
       "      <td>manage that and make sure we stay within the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4-jun-2016</td>\n",
       "      <td>We start at the desk where you have the three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4-jun-2016</td>\n",
       "      <td>It helps to correct this atmosphere which is v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4-jun-2016</td>\n",
       "      <td>Twitter’s live streaming video service announc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204983</th>\n",
       "      <td>1506</td>\n",
       "      <td>30-dec-2016</td>\n",
       "      <td>The former Bishop of Liverpool, JamesJones, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204984</th>\n",
       "      <td>1506</td>\n",
       "      <td>30-dec-2016</td>\n",
       "      <td>Southern rail passengers have been warned that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204985</th>\n",
       "      <td>1506</td>\n",
       "      <td>30-dec-2016</td>\n",
       "      <td>So on the eve of the new year, | make this cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204986</th>\n",
       "      <td>1506</td>\n",
       "      <td>30-dec-2016</td>\n",
       "      <td>It too says it’s willing to talk but, once aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204987</th>\n",
       "      <td>1506</td>\n",
       "      <td>30-dec-2016</td>\n",
       "      <td>A new year perhaps, but the same old problems ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        partition_id         date  \\\n",
       "0                  0   4-jun-2016   \n",
       "1                  0   4-jun-2016   \n",
       "2                  0   4-jun-2016   \n",
       "3                  0   4-jun-2016   \n",
       "4                  0   4-jun-2016   \n",
       "...              ...          ...   \n",
       "204983          1506  30-dec-2016   \n",
       "204984          1506  30-dec-2016   \n",
       "204985          1506  30-dec-2016   \n",
       "204986          1506  30-dec-2016   \n",
       "204987          1506  30-dec-2016   \n",
       "\n",
       "                                               transcript  \n",
       "0       we would have seen during this weekend and the...  \n",
       "1       manage that and make sure we stay within the g...  \n",
       "2       We start at the desk where you have the three ...  \n",
       "3       It helps to correct this atmosphere which is v...  \n",
       "4       Twitter’s live streaming video service announc...  \n",
       "...                                                   ...  \n",
       "204983  The former Bishop of Liverpool, JamesJones, ch...  \n",
       "204984  Southern rail passengers have been warned that...  \n",
       "204985  So on the eve of the new year, | make this cha...  \n",
       "204986  It too says it’s willing to talk but, once aga...  \n",
       "204987  A new year perhaps, but the same old problems ...  \n",
       "\n",
       "[204988 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df.to_csv('bbc_54_may_apr_partitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partition_df.loc[partition_df.date.str.contains('jan-2014')]['partition_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "enc = load('../models/doc2vec/encoder_{}{}.joblib'.format(year, excluding))\n",
    "\n",
    "def predict(X, topn=3):\n",
    "    preprocessed_X = preprocess_text(X)\n",
    "    vec_X = doc2vec_model.infer_vector(preprocessed_X)\n",
    "    vec_X = vec_X.reshape(1, vec_X.shape[0])\n",
    "    pred = classifier.predict(vec_X)\n",
    "    pred_i = []\n",
    "    for i, p in enumerate(pred[0]):\n",
    "        one_hot = np.zeros(len(pred[0]))\n",
    "        one_hot[i] = 1\n",
    "        pred_i += [(enc.inverse_transform([one_hot])[0][0], p)]\n",
    "    pred_sorted = sorted(pred_i, key=lambda x: x[1], reverse=True)\n",
    "    return pred_sorted[:topn]\n",
    "\n",
    "def predict_with_window(partition):\n",
    "    dt = partition.date\n",
    "    start_dt = dt - timedelta(days=2)\n",
    "    end_dt = dt + timedelta(days=2)\n",
    "    articles_window = articles.loc[(articles['date'] >= start_dt) & (articles['date'] <= end_dt)]\n",
    "    partition_vector = np.array(partition.vector)\n",
    "    partition_vector = partition_vector.reshape(1, 100)\n",
    "    articles_vector = articles_window.vector.values\n",
    "    vec = [articles_vector[i] for i in range(len(articles_vector))]\n",
    "    vec = np.array(vec)\n",
    "    sim = cosine_similarity(partition_vector, vec)\n",
    "    max_index = np.argmax(sim)\n",
    "    \n",
    "    return articles_window.iloc[max_index]['top1_topic']\n",
    "\n",
    "def build_network():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.Input(shape=(100)),\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1)),\n",
    "        tf.keras.layers.Dense(len(enc.categories_[0]), activation='softmax')\n",
    "    ])\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0, name='categorical_crossentropy')\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f896adf1d10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model = Doc2Vec.load('../models/doc2vec/doc2vec_news_{}{}'.format(year, excluding))\n",
    "classifier = build_network()\n",
    "classifier.load_weights('../models/doc2vec/news_classifier_{}{}'.format(year, excluding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df['date'] = pd.to_datetime(partition_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Health services and medicine', 0.7798618),\n",
       " ('Culture, media and sport', 0.1451124),\n",
       " ('International affairs', 0.038704604)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = partition_df.transcript.values\n",
    "predict(transcripts[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The health watchdog, the Care Quality Commission, has apologised to family doctors after a BBC investigation revealed they wrongly classified the risk rating of hundreds of surgeries in England, including wrongly suggesting 60 were of the highest concern. This GP practice in Buckinghamshire was shocked to be branded high risk on a new online database, published by the watchdog the COC. Now, after a BBC investigation which prompted an embarrassing correction, it has been moved to a low risk category. Our patients, seeing that kind of information in the public Main, it would have dented their confidence in us as a practice, and their confidence in us as their GP. Designed to let a ship find out more about their GPs, more than 7000 surgeries in England were placed in six bands according to risk, raced on indicators including ease of appointments, success in diagnosing dementia and levels of heart disease. Now, the COC has admitted that 60 surgeries were wrongly given poor ratings, because it’s statistics were unreliable. Want some of the practices feel their reputation has been damaged by this, and that you owe them a big apology? We are getting in touch with each fact is individually. We will also inform the local media about this, to be completely open about it. This is something which only became apparent when we ran the data on the thousands of practices, rather than just on the hundreds that we had tested it on. GPs’ representatives have never liked this system, saying it was wrong to publish data before full inspections of most surgeries had taken place. One doctors’ organisation said GPs had been badly let down. The continued release of this flawed information should be stopped. They are discrediting many very good practices and misleading patients. It was billed as a nexus eyes in transparency, and for the watchdog to identify surgeries with problems. But right now it is at the centre of its own controversy. There has been a furious reaction in Athens to the decision of the British Museum to loan one of the Elgin Marbles to Russia. The statue of the River God Ilissos was secretly flown to St Petersburg and put on display this morning at the Hermitage Museum. Greece has always claimed the Elgin Marbles were looted by the British from the Parthenon in Athens and demanded their return. It is the first time one of the treasures has left Britain. We were just allowed into the Hermitage this evening ahead of the main public opening of the exhibition tomorrow. I spoke to the generator, who told me that despite all the fuss, Russians are just excited to have such an important work of art here in their country. They said that at a time of such difficult relations between Russia and the West, they see it as a gesture of friendship. This is Ilissos, now on loan to the Hermitage Museum in St Petersburg. Because this is a cultural exchange with the potential to spark a political storm.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts[55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/207 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8516bca7a897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscripts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "from tqdm import tqdm\n",
    "for transcript in tqdm(transcripts):\n",
    "    predictions.append(predict(transcript))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0fc765a49d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpartition_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "partition_df['topic'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition_id</th>\n",
       "      <th>date</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>521</td>\n",
       "      <td>2-apr-2016</td>\n",
       "      <td>between them created an artificially intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>521</td>\n",
       "      <td>2-apr-2016</td>\n",
       "      <td>The Xbox connects we are using in this space w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521</td>\n",
       "      <td>2-apr-2016</td>\n",
       "      <td>Our home state of Arizona is overrun by home s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>521</td>\n",
       "      <td>2-apr-2016</td>\n",
       "      <td>The goal was to blur the lines between what’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>521</td>\n",
       "      <td>2-apr-2016</td>\n",
       "      <td>Don’t forget you can still immerse Don’t forge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11860</th>\n",
       "      <td>1284</td>\n",
       "      <td>31-may-2016</td>\n",
       "      <td>What to know what a Donald Trump residency wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11861</th>\n",
       "      <td>1284</td>\n",
       "      <td>31-may-2016</td>\n",
       "      <td>We will be talking to one of its foreign polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>1284</td>\n",
       "      <td>31-may-2016</td>\n",
       "      <td>Tonight we reveal startling new figures showin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11863</th>\n",
       "      <td>1284</td>\n",
       "      <td>31-may-2016</td>\n",
       "      <td>Along with more affordable homes, Sadiq Khan h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11864</th>\n",
       "      <td>1284</td>\n",
       "      <td>31-may-2016</td>\n",
       "      <td>We have seen a massive increase in the numbers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11865 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       partition_id         date  \\\n",
       "0               521   2-apr-2016   \n",
       "1               521   2-apr-2016   \n",
       "2               521   2-apr-2016   \n",
       "3               521   2-apr-2016   \n",
       "4               521   2-apr-2016   \n",
       "...             ...          ...   \n",
       "11860          1284  31-may-2016   \n",
       "11861          1284  31-may-2016   \n",
       "11862          1284  31-may-2016   \n",
       "11863          1284  31-may-2016   \n",
       "11864          1284  31-may-2016   \n",
       "\n",
       "                                              transcript  \n",
       "0      between them created an artificially intellige...  \n",
       "1      The Xbox connects we are using in this space w...  \n",
       "2      Our home state of Arizona is overrun by home s...  \n",
       "3      The goal was to blur the lines between what’s ...  \n",
       "4      Don’t forget you can still immerse Don’t forge...  \n",
       "...                                                  ...  \n",
       "11860  What to know what a Donald Trump residency wou...  \n",
       "11861  We will be talking to one of its foreign polic...  \n",
       "11862  Tonight we reveal startling new figures showin...  \n",
       "11863  Along with more affordable homes, Sadiq Khan h...  \n",
       "11864  We have seen a massive increase in the numbers...  \n",
       "\n",
       "[11865 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition_df = partition_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition_df.to_csv('bbc_predictions_{}_{}.csv'.format(bbc_id, year))\n",
    "partition_df.to_csv('bbc_predictions_News_at_One_Six_Ten.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:econ] *",
   "language": "python",
   "name": "conda-env-econ-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
